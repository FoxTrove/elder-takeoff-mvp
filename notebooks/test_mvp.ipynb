{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Takeoff MVP - Inference/Testing Notebook\n",
    "\n",
    "This notebook loads your trained YOLOv8 model and runs detection on test images to count construction elements.\n",
    "\n",
    "## Prerequisites\n",
    "- Trained model at `../models/best.pt`\n",
    "- Test blueprint images to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your trained model\n",
    "model_path = Path('../models/best.pt')\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"‚ùå Model not found! Please run train_mvp.ipynb first.\")\n",
    "    print(f\"Looking for model at: {model_path.absolute()}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loading model from: {model_path.absolute()}\")\n",
    "    model = YOLO(str(model_path))\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # Display model info\n",
    "    print(f\"\\nüìä Model Information:\")\n",
    "    print(f\"Classes: {model.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select Test Image\n",
    "\n",
    "Choose an image to test. You can:\n",
    "- Use an image from your training set (to verify the model works)\n",
    "- Use a new, unseen blueprint image (to test real-world performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Specify a direct path to your test image\n",
    "test_image_path = '../data_raw/your_test_image.png'  # ‚¨ÖÔ∏è CHANGE THIS\n",
    "\n",
    "# Option 2: Or select from labeled images\n",
    "# Uncomment the lines below to use an image from your training set\n",
    "# images_dir = Path('../data_labeled/images')\n",
    "# image_files = list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpg'))\n",
    "# if image_files:\n",
    "#     test_image_path = str(image_files[0])  # Use first image\n",
    "#     print(f\"Using image: {Path(test_image_path).name}\")\n",
    "\n",
    "print(f\"Test image: {test_image_path}\")\n",
    "\n",
    "# Verify the image exists\n",
    "if not Path(test_image_path).exists():\n",
    "    print(\"\\n‚ö†Ô∏è  Image not found! Please update the test_image_path variable above.\")\n",
    "    print(\"\\nAvailable images in data_labeled/images:\")\n",
    "    images_dir = Path('../data_labeled/images')\n",
    "    if images_dir.exists():\n",
    "        for img in images_dir.glob('*'):\n",
    "            if img.suffix.lower() in ['.png', '.jpg', '.jpeg']:\n",
    "                print(f\"  - {img.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Detection\n",
    "\n",
    "This is the core inference step - the model will detect objects and count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print(\"üîç Running detection...\\n\")\n",
    "\n",
    "# Perform detection\n",
    "# conf: confidence threshold (0.25 = 25% confidence minimum)\n",
    "# iou: intersection over union threshold for NMS\n",
    "results = model(test_image_path, conf=0.25, iou=0.45)\n",
    "\n",
    "print(\"‚úÖ Detection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract and Display Results\n",
    "\n",
    "### üéØ This is the MVP deliverable: Object count for takeoff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results\n",
    "for result in results:\n",
    "    # Get bounding boxes\n",
    "    boxes = result.boxes\n",
    "    \n",
    "    # Total count\n",
    "    total_count = len(boxes)\n",
    "    \n",
    "    # Count by class\n",
    "    class_counts = {}\n",
    "    for box in boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "    \n",
    "    # Display results\n",
    "    print(\"=\"*50)\n",
    "    print(\"üéØ TAKEOFF RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nüìä Total Objects Detected: {total_count}\")\n",
    "    print(\"\\nüìã Breakdown by Type:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"   ‚Ä¢ {class_name}: {count}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Get confidence scores\n",
    "    if total_count > 0:\n",
    "        confidences = boxes.conf.cpu().numpy()\n",
    "        avg_confidence = np.mean(confidences)\n",
    "        min_confidence = np.min(confidences)\n",
    "        max_confidence = np.max(confidences)\n",
    "        \n",
    "        print(f\"\\nüìà Confidence Statistics:\")\n",
    "        print(f\"   ‚Ä¢ Average: {avg_confidence:.2%}\")\n",
    "        print(f\"   ‚Ä¢ Range: {min_confidence:.2%} - {max_confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results\n",
    "\n",
    "Display the blueprint image with bounding boxes drawn around detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "for result in results:\n",
    "    # Get annotated image\n",
    "    annotated_img = result.plot(\n",
    "        conf=True,        # Show confidence scores\n",
    "        line_width=2,     # Bounding box line width\n",
    "        font_size=12      # Label font size\n",
    "    )\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(annotated_img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Detection Results: {total_count} objects detected', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Optionally save the annotated image\n",
    "    output_path = Path('../models/detection_result.jpg')\n",
    "    cv2.imwrite(str(output_path), annotated_img)\n",
    "    print(f\"\\nüíæ Annotated image saved to: {output_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed Detection Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed information for each detection\n",
    "print(\"\\nüìù Detailed Detection List:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        print(\"No objects detected.\")\n",
    "    else:\n",
    "        for idx, box in enumerate(boxes, 1):\n",
    "            # Get box data\n",
    "            class_id = int(box.cls[0])\n",
    "            class_name = model.names[class_id]\n",
    "            confidence = float(box.conf[0])\n",
    "            \n",
    "            # Get bounding box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            \n",
    "            print(f\"\\n{idx}. {class_name.upper()}\")\n",
    "            print(f\"   Confidence: {confidence:.2%}\")\n",
    "            print(f\"   Location: ({int(x1)}, {int(y1)}) to ({int(x2)}, {int(y2)})\")\n",
    "            print(f\"   Size: {int(x2-x1)} x {int(y2-y1)} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing (Optional)\n",
    "\n",
    "Process multiple images at once and generate a summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images in a directory\n",
    "def process_directory(directory_path, output_csv=None):\n",
    "    \"\"\"\n",
    "    Process all images in a directory and optionally save results to CSV.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    directory = Path(directory_path)\n",
    "    image_files = list(directory.glob('*.png')) + list(directory.glob('*.jpg')) + list(directory.glob('*.jpeg'))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {directory}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìÅ Processing {len(image_files)} images from {directory.name}...\\n\")\n",
    "    \n",
    "    results_data = []\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        # Run detection\n",
    "        results = model(str(img_path), conf=0.25, verbose=False)\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            total_count = len(boxes)\n",
    "            \n",
    "            # Count by class\n",
    "            class_counts = {}\n",
    "            for box in boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = model.names[class_id]\n",
    "                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "            \n",
    "            # Store results\n",
    "            result_row = {\n",
    "                'filename': img_path.name,\n",
    "                'total_count': total_count,\n",
    "                **class_counts\n",
    "            }\n",
    "            results_data.append(result_row)\n",
    "            \n",
    "            print(f\"‚úÖ {img_path.name}: {total_count} objects\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results_data).fillna(0)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Total objects across all images: {int(df['total_count'].sum())}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save to CSV if requested\n",
    "    if output_csv:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nüíæ Results saved to: {output_csv}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# results_df = process_directory('../data_labeled/images', output_csv='../models/takeoff_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adjust Confidence Threshold (Optional)\n",
    "\n",
    "If you're getting too many false positives or missing objects, adjust the confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different confidence thresholds\n",
    "confidence_thresholds = [0.15, 0.25, 0.35, 0.50]\n",
    "\n",
    "print(\"üî¨ Testing different confidence thresholds:\\n\")\n",
    "\n",
    "for conf_threshold in confidence_thresholds:\n",
    "    results = model(test_image_path, conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    for result in results:\n",
    "        count = len(result.boxes)\n",
    "        print(f\"Confidence {conf_threshold:.0%}: {count} objects detected\")\n",
    "\n",
    "print(\"\\nüí° Tip: Lower threshold = more detections (but more false positives)\")\n",
    "print(\"        Higher threshold = fewer detections (but more accurate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **MVP Deliverable Complete!**\n",
    "\n",
    "You now have:\n",
    "1. ‚úÖ A trained YOLOv8 model for construction element detection\n",
    "2. ‚úÖ Inference capability on blueprint images\n",
    "3. ‚úÖ **Automated object counting for takeoff quantities**\n",
    "4. ‚úÖ Visual output with bounding boxes\n",
    "5. ‚úÖ Batch processing capability\n",
    "\n",
    "### Next Steps:\n",
    "- **Improve accuracy**: Add more labeled training data\n",
    "- **Add more classes**: Detect doors, windows, fixtures, etc.\n",
    "- **Optimize performance**: Try larger models (yolov8s, yolov8m) for better accuracy\n",
    "- **Production deployment**: Create a web interface or API\n",
    "- **Integration**: Connect to your takeoff/estimation software\n",
    "\n",
    "### Production Considerations:\n",
    "- Save detection results to a database\n",
    "- Generate PDF reports with annotated images\n",
    "- Track confidence scores for quality control\n",
    "- Implement human review workflow for low-confidence detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
